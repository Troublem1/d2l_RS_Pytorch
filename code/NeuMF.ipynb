{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuMF model:\n",
    "\n",
    "<img src=\"../data/img/NeuMF_model.png\" height=\"600\" width=\"600\" style=\"float:left\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评价指标：\n",
    "\n",
    "* Hit Rate\n",
    "\n",
    "$$Hit@l = \\frac{1}{m}\\sum_{u\\in \\mathrm{U}} 1(rank_{u,g_u} <= l)$$\n",
    "\n",
    "* AUC\n",
    "\n",
    "$$AUC = \\frac{1}{m}\\sum_{u\\in \\mathrm{U}} \\frac{1}{\\vert I \\backslash S_u \\vert} \\sum _{j \\in I \\backslash S_u}1(rank_{u,g_u} < rank{u,j})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/ml-100k/u.data'\n",
    "BATCH_SIZE = 512\n",
    "data = pd.read_csv(path,sep='\\t',header=None,names=['user_id', 'item_id', 'rating', 'timestamp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users = data.user_id.unique().shape[0]+1\n",
    "num_items = data.item_id.unique().shape[0]+1\n",
    "num_factors=10\n",
    "mlp_layer = [[num_factors*2, num_factors],[num_factors,num_factors],[num_factors,num_factors]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_factors, num_users, num_items, mlp_layer):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.P = nn.Embedding(num_embeddings=num_users, embedding_dim=num_factors)\n",
    "        self.Q = nn.Embedding(num_embeddings=num_items, embedding_dim=num_factors)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.U = nn.Embedding(num_embeddings=num_users, embedding_dim=num_factors)\n",
    "        self.V = nn.Embedding(num_embeddings=num_items, embedding_dim=num_factors)\n",
    "        self.mlp = nn.Sequential()\n",
    "        for i,layer in enumerate(mlp_layer):\n",
    "            self.mlp.add_module('layer'+str(i+1),nn.Linear(layer[0], layer[1]))\n",
    "            self.mlp.add_module('relu'+str(i+1),nn.ReLU())\n",
    "    \n",
    "    def forward(self, data):\n",
    "        user_id, item_id = data[:,0], data[:,1]\n",
    "        p = self.P(user_id)\n",
    "        q = self.Q(item_id)\n",
    "        b_p = self.user_bias(user_id)\n",
    "        b_q = self.item_bias(item_id)\n",
    "        mf_output = ((p*q).sum(dim=1)) + b_p.squeeze() + b_q.squeeze()\n",
    "        u = self.U(user_id)\n",
    "        v = self.V(item_id)\n",
    "        mlp_input = torch.cat((u, v), dim=1)\n",
    "        mlp_output = self.mlp(mlp_input).sum(dim=1)\n",
    "        return mf_output+mlp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NeuMF(num_factors, num_users, num_items, mlp_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuMF(\n",
      "  (P): Embedding(944, 10)\n",
      "  (Q): Embedding(1683, 10)\n",
      "  (user_bias): Embedding(944, 1)\n",
      "  (item_bias): Embedding(1683, 1)\n",
      "  (U): Embedding(944, 10)\n",
      "  (V): Embedding(1683, 10)\n",
      "  (mlp): Sequential(\n",
      "    (layer1): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['user_id', 'item_id']].values, data['rating'].values, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train,dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset = Data.TensorDataset(X_train,y_train),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(y, y_):\n",
    "    loss = ((y-y_)**2).sum()\n",
    "    loss = loss/len(y)\n",
    "    return loss**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(nmf.parameters(), lr=0.02, weight_decay=0.0001)\n",
    "loss_func = RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0|train_loss : 4.967004776000977| test_loss :4.707469940185547\n",
      "Epoch : 1|train_loss : 1.0342140197753906| test_loss :1.1050599813461304\n",
      "Epoch : 2|train_loss : 0.9001923203468323| test_loss :0.9801263213157654\n",
      "Epoch : 3|train_loss : 0.8529559373855591| test_loss :0.9584418535232544\n",
      "Epoch : 4|train_loss : 0.8460323214530945| test_loss :0.9351161122322083\n",
      "Epoch : 5|train_loss : 0.8072608113288879| test_loss :0.9267516732215881\n",
      "Epoch : 6|train_loss : 0.8310391306877136| test_loss :0.9247966408729553\n",
      "Epoch : 7|train_loss : 0.8483110666275024| test_loss :0.9202793836593628\n",
      "Epoch : 8|train_loss : 0.7432692646980286| test_loss :0.9180523157119751\n",
      "Epoch : 9|train_loss : 0.7926887273788452| test_loss :0.9198423027992249\n",
      "Epoch : 10|train_loss : 0.8047158122062683| test_loss :0.9216089844703674\n",
      "Epoch : 11|train_loss : 0.7863147258758545| test_loss :0.9174734950065613\n",
      "Epoch : 12|train_loss : 0.779283344745636| test_loss :0.9187537431716919\n",
      "Epoch : 13|train_loss : 0.8250163793563843| test_loss :0.9186773896217346\n",
      "Epoch : 14|train_loss : 0.7327274084091187| test_loss :0.9164828658103943\n",
      "Epoch : 15|train_loss : 0.7795493006706238| test_loss :0.9213581085205078\n",
      "Epoch : 16|train_loss : 0.7950015664100647| test_loss :0.920018196105957\n",
      "Epoch : 17|train_loss : 0.7728696465492249| test_loss :0.9200742840766907\n",
      "Epoch : 18|train_loss : 0.7990171909332275| test_loss :0.9177647233009338\n",
      "Epoch : 19|train_loss : 0.7661552429199219| test_loss :0.9200298190116882\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20) :\n",
    "    for step, (tx, ty) in enumerate(train_loader) :\n",
    "        output=nmf(tx)\n",
    "        train_loss = loss_func(output, ty)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 300 == 0 :\n",
    "            with torch.no_grad(): \n",
    "                y = nmf(X_test)\n",
    "                test_loss = loss_func(y, y_test)\n",
    "                print('Epoch : {}|train_loss : {:.4f}| test_loss :{:.4f}'.format(epoch, train_loss.item(), test_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
